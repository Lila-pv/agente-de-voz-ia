<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Agente de Voz IA (Gemini)</title>
    <!-- Carga Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Estilos generales */
        body {
            font-family: 'Inter', sans-serif;
            background-color: #e5e7eb; /* Gris claro */
        }
        /* Clase para el efecto de escucha en el botón del micrófono */
        .listening {
            animation: pulse-ring 1.5s cubic-bezier(0.64, 0, 0.78, 0) infinite;
        }
        @keyframes pulse-ring {
            0% {
                box-shadow: 0 0 0 0 rgba(37, 99, 235, 0.7); /* blue-600 */
            }
            80% {
                box-shadow: 0 0 0 20px rgba(37, 99, 235, 0);
            }
            100% {
                box-shadow: 0 0 0 0 rgba(37, 99, 235, 0);
            }
        }
    </style>
</head>
<body class="flex flex-col items-center justify-center min-h-screen p-4">

    <div class="w-full max-w-lg bg-white rounded-2xl shadow-2xl p-6 flex flex-col h-[85vh]">
        <h1 class="text-3xl font-bold text-gray-800 text-center mb-2">Asistente de Voz Gemini</h1>
        <p id="status" class="text-sm text-center text-blue-600 mb-4 h-5">Pulsa el micrófono o escribe tu pregunta.</p>

        <!-- Contenedor de Conversación -->
        <div id="chat-history" class="flex-grow overflow-y-auto space-y-4 p-3 border border-gray-200 rounded-xl bg-gray-50 mb-6">
            <!-- Los mensajes se insertarán aquí -->
        </div>

        <!-- Área de Controles -->
        <div class="flex flex-col items-center space-y-4">
            
            <!-- Entrada de Texto (NUEVO) -->
            <div class="w-full flex space-x-2">
                <input type="text" id="text-input" placeholder="Escribe tu pregunta aquí..."
                       class="flex-grow p-3 border border-gray-300 rounded-lg focus:ring-blue-500 focus:border-blue-500 transition duration-150">
                <button id="send-button" onclick="sendTextQuery()"
                        class="p-3 bg-green-500 text-white rounded-lg shadow-md hover:bg-green-600 transition duration-150">
                    <!-- Icono de Enviar (simulado con SVG) -->
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                        <path d="m22 2-7 20-4-9-9-4 20-7z"/>
                    </svg>
                </button>
            </div>
            
            <!-- Separador -->
            <p class="text-xs text-gray-400 py-2">O</p>

            <!-- Botón de Micrófono -->
            <button id="mic-button" 
                    class="p-6 rounded-full bg-blue-600 text-white shadow-xl hover:bg-blue-700 transition duration-300 ease-in-out transform hover:scale-105"
                    onclick="toggleRecognition()">
                <!-- Icono de Micrófono (lucide-react, simulado con SVG) -->
                <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                    <path d="M12 2a3 3 0 0 0-3 3v7a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3z"/><path d="M19 10v2a7 7 0 0 1-14 0v-2"/><line x1="12" x2="12" y1="19" y2="22"/>
                </svg>
            </button>
            <p id="mic-label" class="text-xs text-gray-500">Haz click para hablar</p>
        </div>
        
        <!-- Contenedor para la URL de la fuente (Grounding) -->
        <div id="source-container" class="mt-4 p-2 bg-yellow-50 rounded-lg hidden">
            <p class="text-xs font-semibold text-yellow-800 mb-1">Fuente:</p>
            <a id="source-link" target="_blank" class="text-xs text-yellow-700 hover:text-yellow-900 underline truncate block"></a>
        </div>
    </div>

    <script>
        // --- Configuración de la API y Servicios ---
        const API_KEY = ""; // La clave de API se inyectará en tiempo de ejecución.
        const MODEL = 'gemini-2.5-flash-preview-09-2025';
        const API_URL = `https://generativelanguage.googleapis.com/v1beta/models/${MODEL}:generateContent?key=${API_KEY}`;
        
        // Determinar el objeto de Reconocimiento de Voz compatible con el navegador
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const synth = window.speechSynthesis;
        let recognition = null;
        let isListening = false;

        // Elementos del DOM
        const micButton = document.getElementById('mic-button');
        const statusElement = document.getElementById('status');
        const chatHistory = document.getElementById('chat-history');
        const micLabel = document.getElementById('mic-label');
        const sourceContainer = document.getElementById('source-container');
        const sourceLink = document.getElementById('source-link');
        const textInput = document.getElementById('text-input'); // Nuevo
        const sendButton = document.getElementById('send-button'); // Nuevo

        // Listener para enviar la consulta al presionar Enter (NUEVO)
        textInput.addEventListener('keypress', function(e) {
            if (e.key === 'Enter') {
                sendTextQuery();
            }
        });

        // --- Funciones de Utilidad y UI ---

        /**
         * Actualiza el estado visual y de texto del asistente.
         * @param {string} message Mensaje de estado.
         * @param {boolean} listening Indica si el micrófono está activo.
         * @param {string} color Clase de color de Tailwind (ej: 'text-blue-600', 'text-red-600').
         */
        function updateUIState(message, listening = false, color = 'text-blue-600') {
            statusElement.textContent = message;
            statusElement.className = `text-sm text-center mb-4 h-5 font-medium ${color}`;
            micLabel.textContent = listening ? 'Escuchando...' : 'Haz click para hablar';
            isListening = listening;

            if (listening) {
                micButton.classList.add('listening');
                micButton.classList.remove('bg-blue-600', 'hover:bg-blue-700');
                micButton.classList.add('bg-red-500', 'hover:bg-red-600');
                textInput.disabled = true; // Deshabilitar texto mientras escucha voz
                sendButton.disabled = true;
            } else {
                micButton.classList.remove('listening');
                micButton.classList.remove('bg-red-500', 'hover:bg-red-600');
                micButton.classList.add('bg-blue-600', 'hover:bg-blue-700');
                textInput.disabled = false;
                sendButton.disabled = false;
            }
        }
        
        /**
         * Añade un mensaje al historial de chat.
         * @param {string} text Contenido del mensaje.
         * @param {string} sender 'user' o 'ai'.
         */
        function addMessage(text, sender) {
            const messageDiv = document.createElement('div');
            const isUser = sender === 'user';
            
            messageDiv.className = `flex ${isUser ? 'justify-end' : 'justify-start'}`;
            messageDiv.innerHTML = `
                <div class="max-w-xs md:max-w-md p-3 rounded-xl shadow-md ${
                    isUser 
                        ? 'bg-blue-500 text-white rounded-br-none' 
                        : 'bg-white text-gray-800 rounded-tl-none border border-gray-100'
                }">
                    <p class="font-semibold mb-1 text-xs">${isUser ? 'Tú' : 'Gemini'}</p>
                    <p class="text-sm">${text}</p>
                </div>
            `;
            chatHistory.appendChild(messageDiv);
            chatHistory.scrollTop = chatHistory.scrollHeight; // Desplazar al último mensaje
        }
        
        /**
         * Muestra una fuente de información de Google Search.
         * @param {Object} source Objeto con uri y title.
         */
        function displaySource(source) {
            if (source && source.uri && source.title) {
                sourceLink.href = source.uri;
                sourceLink.textContent = source.title;
                sourceContainer.classList.remove('hidden');
            } else {
                sourceContainer.classList.add('hidden');
            }
        }

        /**
         * Convierte texto a voz usando la API de Síntesis de Voz (TTS).
         * @param {string} text El texto que debe ser hablado.
         */
        function speakResponse(text) {
            if (!synth) {
                console.error("La Síntesis de Voz no es compatible con este navegador.");
                return;
            }
            // Detener cualquier voz anterior para evitar superposiciones
            synth.cancel(); 
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = 'es-ES'; // Establecer el idioma a español
            synth.speak(utterance);
        }
        
        // --- Lógica de la Entrada de Texto (NUEVO) ---
        function sendTextQuery() {
            const query = textInput.value.trim();
            if (query) {
                addMessage(query, 'user');
                textInput.value = ''; // Limpiar la entrada
                getAIResponse(query);
            } else {
                updateUIState("Por favor, escribe algo para empezar.", false, 'text-gray-500');
            }
        }

        // --- Lógica del Reconocimiento de Voz (STT) ---

        /**
         * Inicializa y comienza el reconocimiento de voz.
         */
        function startRecognition() {
            if (!SpeechRecognition) {
                updateUIState("Error: La API de Reconocimiento de Voz no es compatible con este navegador.", false, 'text-red-600');
                return;
            }
            if (statusElement.classList.contains('text-red-600')) {
                updateUIState("Pulsa el micrófono o escribe tu pregunta.");
            }

            if (!recognition) {
                recognition = new SpeechRecognition();
                recognition.continuous = false;
                recognition.lang = 'es-ES';
                recognition.interimResults = false;
                recognition.maxAlternatives = 1;
                
                recognition.onstart = () => {
                    updateUIState("¡Habla ahora! Estoy escuchando...", true);
                };

                recognition.onresult = (event) => {
                    const transcript = event.results[0][0].transcript;
                    addMessage(transcript, 'user');
                    getAIResponse(transcript);
                };

                recognition.onend = () => {
                    if (isListening) {
                        updateUIState("Procesando tu solicitud...");
                    }
                    isListening = false;
                };

                recognition.onerror = (event) => {
                    updateUIState(`Error de voz: ${event.error}. Vuelve a intentarlo.`, false, 'text-red-600');
                    isListening = false;
                    micButton.classList.remove('listening');
                };
            }

            try {
                recognition.start();
            } catch (e) {
                console.error("Error al iniciar el reconocimiento:", e);
                updateUIState("Ya estoy escuchando o hubo un error al iniciar. Intenta de nuevo.", false, 'text-red-600');
                isListening = true; 
                try { recognition.stop(); } catch (stopError) { /* ignore */ }
            }
        }
        
        /**
         * Detiene o inicia el reconocimiento de voz.
         */
        function toggleRecognition() {
            if (isListening && recognition) {
                recognition.stop();
                updateUIState("Grabación detenida. Procesando...");
            } else {
                startRecognition();
            }
        }

        // --- Lógica de la IA (Gemini API) ---

        /**
         * Llama a la API de Gemini con reintento exponencial.
         * @param {string} prompt El texto del usuario para la IA.
         */
        async function getAIResponse(prompt) {
            updateUIState("Pensando... (Gemini está generando la respuesta)");
            
            // Deshabilitar la entrada de texto y el botón de voz mientras se procesa la IA
            textInput.disabled = true;
            sendButton.disabled = true;
            micButton.disabled = true;

            const systemPrompt = "Actúa como un asistente de voz amigable y útil. Responde a las preguntas de forma concisa y natural. Si la pregunta requiere información actualizada, usa las herramientas de búsqueda.";
            
            const payload = {
                contents: [{ parts: [{ text: prompt }] }],
                // Habilitar Google Search para grounding
                tools: [{ "google_search": {} }],
                systemInstruction: {
                    parts: [{ text: systemPrompt }]
                }
            };

            const maxRetries = 3;
            for (let attempt = 0; attempt < maxRetries; attempt++) {
                try {
                    const response = await fetch(API_URL, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(payload)
                    });

                    if (!response.ok) {
                        if (response.status >= 500 && attempt < maxRetries - 1) {
                            const delay = Math.pow(2, attempt) * 1000;
                            await new Promise(resolve => setTimeout(resolve, delay));
                            continue;
                        }
                        const errorBody = await response.text();
                        throw new Error(`Error HTTP ${response.status}. Detalle: ${errorBody.substring(0, 50)}...`);
                    }

                    const result = await response.json();
                    const candidate = result.candidates?.[0];

                    if (candidate && candidate.content?.parts?.[0]?.text) {
                        const aiText = candidate.content.parts[0].text;
                        addMessage(aiText, 'ai');
                        speakResponse(aiText);
                        updateUIState("Listo para la siguiente pregunta.");
                        
                        // Extraer y mostrar fuentes (Grounding)
                        let source = null;
                        const groundingMetadata = candidate.groundingMetadata;
                        if (groundingMetadata && groundingMetadata.groundingAttributions && groundingMetadata.groundingAttributions.length > 0) {
                            const firstSource = groundingMetadata.groundingAttributions[0].web;
                            if (firstSource) {
                                source = {
                                    uri: firstSource.uri,
                                    title: firstSource.title,
                                };
                            }
                        }
                        displaySource(source);
                        
                        // Habilitar entradas
                        textInput.disabled = false;
                        sendButton.disabled = false;
                        micButton.disabled = false;

                        return; // Éxito
                    } else {
                        throw new Error("Respuesta de la IA vacía o inesperada.");
                    }
                } catch (error) {
                    console.error(`Intento ${attempt + 1} fallido:`, error);
                    if (attempt === maxRetries - 1) {
                        const errorMessage = error.message || "Error de red desconocido.";
                        updateUIState(`Error Final (reintento fallido): ${errorMessage}`, false, 'text-red-600');
                        addMessage("Lo siento, no pude procesar tu solicitud. Hubo un error de conexión.", 'ai');
                        speakResponse("Lo siento, no pude procesar tu solicitud.");
                        displaySource(null);
                        
                        // Habilitar entradas
                        textInput.disabled = false;
                        sendButton.disabled = false;
                        micButton.disabled = false;
                    }
                }
            }
        }
    </script>
</body>
</html>